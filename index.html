<!DOCTYPE html>
<!--[if lt IE 8 ]><html class="no-js ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="no-js ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 8)|!(IE)]><!--><html class="no-js" lang="en"> <!--<![endif]-->
<head>

   <!--- Basic Page Needs
   ================================================== -->
  <meta charset="utf-8">
	<title>Marwa ElDiwiny</title>
	<meta name="description" content="Research and Personal Projects">
	<meta name="author" content="anurag">

   <!-- Mobile Specific Metas
   ================================================== -->
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<!-- CSS
    ================================================== -->
   <link rel="stylesheet" href="css/default.css">
	 <link rel="stylesheet" href="css/layout.css">
   <link rel="stylesheet" href="css/academicons/css/academicons.css"/>
   <link rel="stylesheet" href="css/media-queries.css">
   <link rel="stylesheet" href="css/magnific-popup.css">

   <!-- Script
   ================================================== -->
	<script src="js/modernizr.js"></script>

   <!-- Icon
	================================================== -->
	<link rel="shortcut icon" href="mpi.jpg" >

</head>

<body>


   <!-- About Section
   ================================================== -->
   <section id="about">
      <nav id="nav-wrap">

        <a class="mobile-btn" href="#nav-wrap" title="Show navigation">Show navigation</a>
	      <a class="mobile-btn" href="#" title="Hide navigation">Hide navigation</a>

         <ul id="nav" class="nav">
             <li class="current"><a class="smoothscroll" href="#about">About</a></li>
            <li><a class="smoothscroll" href="#publication">Publications</a></li>
            <!--li><a class="smoothscroll" href="#research">Research</a></li-->
	    <li><a class="smoothscroll" href="#podcasting">Podcasting</a></li> 
	    <li><a class="smoothscroll" href="#awards">Awards</a></li> 
            <li><a class="smoothscroll" href="#interests">Interests</a></li>

         </ul> <!-- end #nav -->

      </nav> <!-- end #nav-wrap -->

      <div class="row">

         <div class="three columns">

            <img class="profile-pic"  src="media/photo.png" alt="" />

         </div>

         <div class="nine columns main-col">

            <h1><font color="white">Marwa ElDiwiny</font></h1>

            <h5> <font color="white"> Research Graduate Student, Soft Robotics </font> </h5>
            <!--<h5> <font color="white"> Max Planck Institute for Intelligent Systems </font> </h5> -->
            <font color="white"> marwaeldiwiny1991@gmail.com </font>
            <footer>
              <div class="row">

                           <div class="twelve columns">
                  <ul class="social-links">
                     <li><a href="https://scholar.google.com/citations?user=EIzvLY0AAAAJ&hl=ar" target="_blank"><i class="fa fa-google-scholar"></i></a></li>
                     <li><a href="https://github.com/meldiwin" target="_blank"><i class="fa fa-github"></i></a></li>
                     
                     <li><a href="https://medium.com/@marwaeldiwiny1991" target="_blank"><i class="fa fa-medium"></i></a></li>
                     
                  </ul>
               </div>
              </div>
            </footer>
         </div>

     </div> <!-- end .main-col -->

      </div>

      <p class="scrolldown">
         <a class="smoothscroll" href="#about"><i class="icon-down-circle"></i></a>
      </p>


</section> <!-- About Section End-->

<section id="teaser">

 <div class="row add-bottom">
   <p class="lead">
     This is Marwa ElDiwiny, passionate and hard-working girl. Since that mo-
ment, I set a goal to be one of the women who is going to contribute to robotics
field. When I was little girl, I remember I told my mother, I don’t want to be
an ordinary girl, I want to make a difference in the world.

   </p>
   <p>
   Currently, I am a research graduate student at Inria, France, working on modeling
and simulation miniaturized soft robots. To begin, My research career blossomed
when I was in Minia University where the knowledge I gained there in bachelor and
masters degree prepared me to overcome any challenge in solving problems and
conducting research.</p>

  <h5>Professional Experience  </h5>
  <dl class="lining">
    <dt> 1Nov- present 2018</dt> <dd>  Research Scholar, University of Tartu, Institute of Technology. </dd>
    <dt> Sep 2017- Oct 2018</dt> <dd>  Research Graduate Student, Inria.</dd>
    <dt> May 2017- Sep 2017 </dt> <dd> Research engineer, Inria. </dd>
    <dt> Aug - Oct 2017</dt> <dd> Techwomen Mentee at Google[x], Self Driving Cars ( Waymo), reliability team. </dd>
    <dt> Oct 2012- April 2017 </dt> <dd> Assistant Lecturer, Minia University </dd>
    <dt> Oct 2015</dt> <dd> Master of Science</dd>
    <dt> June 2012 </dt> <dd> Bachelor of Science </dd>
  </ul>
 </div>
</section>
   <!--Publication Section
   ================================================== -->
   <section id="publication">

    <div class="row add-bottom">

         <div class="twelve columns">

            <h1 align="center">Publications</h1>
            <hr>
            <div class="row add-bottom">
              <h2 align=center> Adversarial Collaboration</h2>
              <h3 align=center> Joint Unsupervised Learning of Depth, Camera <br> Motion, Optical Flow and Motion Segmentation </h3>
              <p align="center", class="lead add-bottom">
                Anurag Ranjan, Varun Jampani, Kihwan Kim, Deqing Sun, Jonas Wulff, Michael J. Black
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/ac_tease.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        We address the unsupervised learning of several interconnected problems in low-level vision: single view depth prediction, camera motion estimation, optical flow and segmentation
                        of a video into the static scene and moving regions. Our model is trained without any supervision and achieves state of the art results amongst unsupervised methods.
                      </p>
                      <p class="paper-links" align="center"> <a href="https://ps.is.tuebingen.mpg.de/publications/adversarial-collaboration" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="https://github.com/anuragranj/ac" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/abs/1805.09806" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Generating 3D Faces using Convolutional Mesh Autoencoders </h2>
              <p align="center", class="lead add-bottom">
                Anurag Ranjan, Timo Bolkart, Soubhik Sanyal, Michael J. Black (ECCV 2018)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/coma_faces.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                      A non-linear model for generating 3D faces using a Convolutional Autoencoder that operates directly on meshes. Our model is state of the art in generating diverse
                      range of 3D facial meshes.
                      </p>
                      <p class="paper-links" align="center"> <a href="http://coma.is.tue.mpg.de" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="https://github.com/anuragranj/coma" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/pdf/1807.10267.pdf" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Unsupervised Learning of Multi-Frame Optical Flow with Occlusions </h2>
              <p align="center", class="lead add-bottom">
                Joel Janai, Fatma Güney, Anurag Ranjan, Michael J. Black and Andreas Geiger (ECCV 2018)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="https://ps.is.tue.mpg.de/uploads/publication/image/20263/thumb_lg_joeleccv18.png" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        We propose a framework for unsupervised learning of optical flow and occlusions over multiple frames. Our multi-frame, occlusion-sensitive formulation outperforms existing unsupervised two-frame methods and even produces results on par with some fully supervised methods.
                      </p>
                      <p class="paper-links" align="center"> <a href="https://ps.is.tue.mpg.de/publications/janai2018eccv" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="http://www.cvlibs.net/projects.php"" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="http://www.cvlibs.net/publications/Janai2018ECCV.pdf" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Learning Human Optical Flow </h2>
              <p align="center", class="lead add-bottom">
                Anurag Ranjan, Javier Romero, Michael J. Black (BMVC 2018)
              </p>

                  <div class="row"> <div class="five columns">
                    <iframe width="420" height="200" src="https://www.youtube.com/embed/IFZbsDt9jMw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        Learning optical flow for humans is difficult. So, we created a synthetic dataset with realistic humans and trained a neural network on it.
                      </p>
                      <p class="paper-links" align="center"> <a href="http://humanflow.is.tue.mpg.de" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="https://github.com/anuragranj/humanflow" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/abs/1806.05666" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> SPyNet: Spatial Pyramid Network for Optical Flow </h2>
              <p align="center", class="lead add-bottom">
                Anurag Ranjan, Michael J. Black (CVPR 2017)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/sintel_pyramid.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        SPyNet is the smallest deep network in the world that computes optical flow. It is smaller than Flownet by 97% and outperforms it significanly. Both code and trained models are available.
                      </p>
                      <p class="paper-links" align="center"> <a href="http://spynet.is.tue.mpg.de" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="https://github.com/anuragranj/spynet" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/abs/1611.00850" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Interactive Gaze Driven Animation of the Eye Region </h2>
              <p align="center", class="lead add-bottom">
                Debanga R Neog, João L Cardoso, Anurag Ranjan, Dinesh K Pai (Web3D 2016)
              </p>

                  <div class="row"> <div class="five columns">
                    <iframe width="420" height="200" src="https://www.youtube.com/embed/FSae6RVllwQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        A system for real-time animation of eyes that can be interactively controlled in a WebGL. This is the first system for real-time animation of soft tissue movement around the eyes based on gaze input.                      </p>
                      <p class="paper-links" align="center"> <a href="http://www.cs.ubc.ca/research/eyemoveweb3d16/" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                      <a href="http://www.cs.ubc.ca/research/eyemoveweb3d16/Interactive%20Gaze%20Driven%20Animation%20of%20the%20Eye%20Region.pdf" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Learning Periorbital Soft Tissue Motion </h2>
              <p align="center", class="lead add-bottom">
                Anurag Ranjan (Master's Thesis, UBC 2015)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/periorbit.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        We model the soft tissues around the eyes that are associated with subtle and fast motions and convey emotions during facial expressions. Our data driven model that can efficiently learn and reproduce the complex motion of these periorbital soft tissues.
                        <p class="paper-links" align="center"> <a href="https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0166703" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="media/Learning_Periorbital_Soft_Tissue_Motion.pdf" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Implementation of 3D object recognition and tracking </h2>
              <p align="center", class="lead add-bottom">
                Pankaj Bongale, Anurag Ranjan, Sahil Anand (RACSS 2012)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/obj_recog_pcl.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        This object recognition and tracking system utilizes the depth information from a low-cost depth sensor. This approach makes use of the depth information and 3d properties of objects inorder to accurately identify them independent of lighting conditions.
                        <p class="paper-links" align="center">
                        <a href="media/object_recognition_point_clouds.pdf" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

         </div>

      </div> <!-- Row End-->

   </section> <!-- Research Section End-->

	  <section id="podcasting">
  <!-- Awards Section
	   <section id="awards">
	  
			       

      <!-- Bio Section

   ================================================== -->
   <section id="interests">
     <div class="row add-bottom">
        <div class="twelve columns" align="center">
          <h1>Bio</h1>
          <p> I am passionate about inspiration from the mother nature thats why I dedicate myself for conducting research towards understanding the physics behind the actuation mechanism of artificial muscle ( Ionic Electro-active polymer), for more details about me you can have a look on my resumé <a href="media/Resumé.pdf
" target="_blank" title="Resumé"> here </a>.

          </p>
          <p> I am doing podcasting, you can listen through those links <a href="http://little-dropsofwater.blogspot.de/" target="_blank">  </a>. </p>
        </div>
     </div>


   </section>
  <small> Template from <a href="http://www.Styleshout.com">http://www.Styleshout.com</a> </small>
   <!-- Java Script
   ================================================== -->
   <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
   <script>window.jQuery || document.write('<script src="js/jquery-1.10.2.min.js"><\/script>')</script>
   <script type="text/javascript" src="js/jquery-migrate-1.2.1.min.js"></script>

   <script src="js/jquery.flexslider.js"></script>
   <script src="js/waypoints.js"></script>
   <script src="js/jquery.fittext.js"></script>
   <script src="js/magnific-popup.js"></script>
   <script src="js/init.js"></script>
   <script>
  	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-105425042-1', 'auto');
  	ga('send', 'pageview');
  </script>

</body>

</html>
